digraph {
	graph [size="228.6,228.6"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13985372144 [label="
 (1, 18)" fillcolor=darkolivegreen1]
	13985211936 [label=AddmmBackward0]
	13985211792 -> 13985211936
	13828350288 [label="fc.bias
 (18)" fillcolor=lightblue]
	13828350288 -> 13985211792
	13985211792 [label=AccumulateGrad]
	13985211744 -> 13985211936
	13985211744 [label=ViewBackward0]
	13985211648 -> 13985211744
	13985211648 [label=MeanBackward1]
	13985211504 -> 13985211648
	13985211504 [label=ReluBackward0]
	13985211264 -> 13985211504
	13985211264 [label=AddBackward0]
	13985211168 -> 13985211264
	13985211168 [label=ReluBackward0]
	13985211024 -> 13985211168
	13985211024 [label=AddBackward0]
	13985210928 -> 13985211024
	13985210928 [label=NativeBatchNormBackward0]
	13985210688 -> 13985210928
	13985210688 [label=ConvolutionBackward0]
	13985210400 -> 13985210688
	13985210400 [label=ReluBackward0]
	13985212464 -> 13985210400
	13985212464 [label=AddBackward0]
	13985212560 -> 13985212464
	13985212560 [label=ReluBackward0]
	13985212704 -> 13985212560
	13985212704 [label=AddBackward0]
	13985212800 -> 13985212704
	13985212800 [label=ReluBackward0]
	13985212944 -> 13985212800
	13985212944 [label=AddBackward0]
	13985213040 -> 13985212944
	13985213040 [label=ReluBackward0]
	13985213184 -> 13985213040
	13985213184 [label=AddBackward0]
	13985213280 -> 13985213184
	13985213280 [label=ReluBackward0]
	13985213424 -> 13985213280
	13985213424 [label=AddBackward0]
	13985213520 -> 13985213424
	13985213520 [label=ReluBackward0]
	13985213664 -> 13985213520
	13985213664 [label=AddBackward0]
	13985213760 -> 13985213664
	13985213760 [label=ReluBackward0]
	13985213904 -> 13985213760
	13985213904 [label=AddBackward0]
	13985214000 -> 13985213904
	13985214000 [label=ReluBackward0]
	13985214144 -> 13985214000
	13985214144 [label=AddBackward0]
	13985214240 -> 13985214144
	13985214240 [label=ReluBackward0]
	13985214384 -> 13985214240
	13985214384 [label=AddBackward0]
	13985214480 -> 13985214384
	13985214480 [label=ReluBackward0]
	13985214624 -> 13985214480
	13985214624 [label=AddBackward0]
	13985214720 -> 13985214624
	13985214720 [label=ReluBackward0]
	13985214864 -> 13985214720
	13985214864 [label=AddBackward0]
	13985214960 -> 13985214864
	13985214960 [label=ReluBackward0]
	13985215104 -> 13985214960
	13985215104 [label=AddBackward0]
	13985215200 -> 13985215104
	13985215200 [label=ReluBackward0]
	13985215344 -> 13985215200
	13985215344 [label=AddBackward0]
	13985215440 -> 13985215344
	13985215440 [label=ReluBackward0]
	13985215584 -> 13985215440
	13985215584 [label=AddBackward0]
	13985215680 -> 13985215584
	13985215680 [label=ReluBackward0]
	13985215824 -> 13985215680
	13985215824 [label=AddBackward0]
	13985215920 -> 13985215824
	13985215920 [label=NativeBatchNormBackward0]
	13985216064 -> 13985215920
	13985216064 [label=ConvolutionBackward0]
	13985216256 -> 13985216064
	13985216256 [label=ReluBackward0]
	13985216400 -> 13985216256
	13985216400 [label=AddBackward0]
	13985216496 -> 13985216400
	13985216496 [label=ReluBackward0]
	13985216640 -> 13985216496
	13985216640 [label=AddBackward0]
	13985216736 -> 13985216640
	13985216736 [label=ReluBackward0]
	13985216880 -> 13985216736
	13985216880 [label=AddBackward0]
	13985216976 -> 13985216880
	13985216976 [label=ReluBackward0]
	13985217120 -> 13985216976
	13985217120 [label=AddBackward0]
	13985217216 -> 13985217120
	13985217216 [label=ReluBackward0]
	13985217360 -> 13985217216
	13985217360 [label=AddBackward0]
	13985217456 -> 13985217360
	13985217456 [label=ReluBackward0]
	13985217600 -> 13985217456
	13985217600 [label=AddBackward0]
	13985217696 -> 13985217600
	13985217696 [label=NativeBatchNormBackward0]
	13985217840 -> 13985217696
	13985217840 [label=ConvolutionBackward0]
	13985218032 -> 13985217840
	13985218032 [label=ReluBackward0]
	13985218176 -> 13985218032
	13985218176 [label=AddBackward0]
	13985218272 -> 13985218176
	13985218272 [label=ReluBackward0]
	13985218416 -> 13985218272
	13985218416 [label=AddBackward0]
	13985218512 -> 13985218416
	13985218512 [label=NativeBatchNormBackward0]
	13985431712 -> 13985218512
	13985431712 [label=ConvolutionBackward0]
	13985431904 -> 13985431712
	13985431904 [label=ReluBackward0]
	13985432048 -> 13985431904
	13985432048 [label=NativeBatchNormBackward0]
	13985432144 -> 13985432048
	13985432144 [label=ConvolutionBackward0]
	13985432336 -> 13985432144
	13828771472 [label="stem.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	13828771472 -> 13985432336
	13985432336 [label=AccumulateGrad]
	13985432096 -> 13985432048
	13828772816 [label="stem.1.weight
 (32)" fillcolor=lightblue]
	13828772816 -> 13985432096
	13985432096 [label=AccumulateGrad]
	13985431952 -> 13985432048
	13881150160 [label="stem.1.bias
 (32)" fillcolor=lightblue]
	13881150160 -> 13985431952
	13985431952 [label=AccumulateGrad]
	13985431856 -> 13985431712
	13881156304 [label="trunk_output.block1.block1-0.proj.0.weight
 (96, 32, 1, 1)" fillcolor=lightblue]
	13881156304 -> 13985431856
	13985431856 [label=AccumulateGrad]
	13985431664 -> 13985218512
	13881156400 [label="trunk_output.block1.block1-0.proj.1.weight
 (96)" fillcolor=lightblue]
	13881156400 -> 13985431664
	13985431664 [label=AccumulateGrad]
	13985431616 -> 13985218512
	13881156496 [label="trunk_output.block1.block1-0.proj.1.bias
 (96)" fillcolor=lightblue]
	13881156496 -> 13985431616
	13985431616 [label=AccumulateGrad]
	13985218464 -> 13985218416
	13985218464 [label=NativeBatchNormBackward0]
	13985432288 -> 13985218464
	13985432288 [label=ConvolutionBackward0]
	13985432384 -> 13985432288
	13985432384 [label=ReluBackward0]
	13985432528 -> 13985432384
	13985432528 [label=NativeBatchNormBackward0]
	13985432624 -> 13985432528
	13985432624 [label=ConvolutionBackward0]
	13985432816 -> 13985432624
	13985432816 [label=ReluBackward0]
	13985432960 -> 13985432816
	13985432960 [label=NativeBatchNormBackward0]
	13985433056 -> 13985432960
	13985433056 [label=ConvolutionBackward0]
	13985431904 -> 13985433056
	13985433248 -> 13985433056
	13881156880 [label="trunk_output.block1.block1-0.f.a.0.weight
 (96, 32, 1, 1)" fillcolor=lightblue]
	13881156880 -> 13985433248
	13985433248 [label=AccumulateGrad]
	13985433008 -> 13985432960
	13881156976 [label="trunk_output.block1.block1-0.f.a.1.weight
 (96)" fillcolor=lightblue]
	13881156976 -> 13985433008
	13985433008 [label=AccumulateGrad]
	13985432864 -> 13985432960
	13881157072 [label="trunk_output.block1.block1-0.f.a.1.bias
 (96)" fillcolor=lightblue]
	13881157072 -> 13985432864
	13985432864 [label=AccumulateGrad]
	13985432768 -> 13985432624
	13881157456 [label="trunk_output.block1.block1-0.f.b.0.weight
 (96, 48, 3, 3)" fillcolor=lightblue]
	13881157456 -> 13985432768
	13985432768 [label=AccumulateGrad]
	13985432576 -> 13985432528
	13881157552 [label="trunk_output.block1.block1-0.f.b.1.weight
 (96)" fillcolor=lightblue]
	13881157552 -> 13985432576
	13985432576 [label=AccumulateGrad]
	13985432240 -> 13985432528
	13881157648 [label="trunk_output.block1.block1-0.f.b.1.bias
 (96)" fillcolor=lightblue]
	13881157648 -> 13985432240
	13985432240 [label=AccumulateGrad]
	13985432432 -> 13985432288
	13881158032 [label="trunk_output.block1.block1-0.f.c.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	13881158032 -> 13985432432
	13985432432 [label=AccumulateGrad]
	13985431808 -> 13985218464
	13881158128 [label="trunk_output.block1.block1-0.f.c.1.weight
 (96)" fillcolor=lightblue]
	13881158128 -> 13985431808
	13985431808 [label=AccumulateGrad]
	13985431760 -> 13985218464
	13881158224 [label="trunk_output.block1.block1-0.f.c.1.bias
 (96)" fillcolor=lightblue]
	13881158224 -> 13985431760
	13985431760 [label=AccumulateGrad]
	13985218224 -> 13985218176
	13985218224 [label=NativeBatchNormBackward0]
	13985218320 -> 13985218224
	13985218320 [label=ConvolutionBackward0]
	13985432480 -> 13985218320
	13985432480 [label=ReluBackward0]
	13985432912 -> 13985432480
	13985432912 [label=NativeBatchNormBackward0]
	13985433296 -> 13985432912
	13985433296 [label=ConvolutionBackward0]
	13985433488 -> 13985433296
	13985433488 [label=ReluBackward0]
	13985433632 -> 13985433488
	13985433632 [label=NativeBatchNormBackward0]
	13985433728 -> 13985433632
	13985433728 [label=ConvolutionBackward0]
	13985218272 -> 13985433728
	13985433920 -> 13985433728
	13881158608 [label="trunk_output.block1.block1-1.f.a.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	13881158608 -> 13985433920
	13985433920 [label=AccumulateGrad]
	13985433680 -> 13985433632
	13881158704 [label="trunk_output.block1.block1-1.f.a.1.weight
 (96)" fillcolor=lightblue]
	13881158704 -> 13985433680
	13985433680 [label=AccumulateGrad]
	13985433536 -> 13985433632
	13881158800 [label="trunk_output.block1.block1-1.f.a.1.bias
 (96)" fillcolor=lightblue]
	13881158800 -> 13985433536
	13985433536 [label=AccumulateGrad]
	13985433440 -> 13985433296
	13881159184 [label="trunk_output.block1.block1-1.f.b.0.weight
 (96, 48, 3, 3)" fillcolor=lightblue]
	13881159184 -> 13985433440
	13985433440 [label=AccumulateGrad]
	13985433344 -> 13985432912
	13881159280 [label="trunk_output.block1.block1-1.f.b.1.weight
 (96)" fillcolor=lightblue]
	13881159280 -> 13985433344
	13985433344 [label=AccumulateGrad]
	13985433200 -> 13985432912
	13881159376 [label="trunk_output.block1.block1-1.f.b.1.bias
 (96)" fillcolor=lightblue]
	13881159376 -> 13985433200
	13985433200 [label=AccumulateGrad]
	13985432672 -> 13985218320
	13881159760 [label="trunk_output.block1.block1-1.f.c.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	13881159760 -> 13985432672
	13985432672 [label=AccumulateGrad]
	13985218368 -> 13985218224
	13881159856 [label="trunk_output.block1.block1-1.f.c.1.weight
 (96)" fillcolor=lightblue]
	13881159856 -> 13985218368
	13985218368 [label=AccumulateGrad]
	13985432192 -> 13985218224
	13881159952 [label="trunk_output.block1.block1-1.f.c.1.bias
 (96)" fillcolor=lightblue]
	13881159952 -> 13985432192
	13985432192 [label=AccumulateGrad]
	13985217984 -> 13985217840
	13881160336 [label="trunk_output.block2.block2-0.proj.0.weight
 (192, 96, 1, 1)" fillcolor=lightblue]
	13881160336 -> 13985217984
	13985217984 [label=AccumulateGrad]
	13985217792 -> 13985217696
	13881160432 [label="trunk_output.block2.block2-0.proj.1.weight
 (192)" fillcolor=lightblue]
	13881160432 -> 13985217792
	13985217792 [label=AccumulateGrad]
	13985217744 -> 13985217696
	13881160528 [label="trunk_output.block2.block2-0.proj.1.bias
 (192)" fillcolor=lightblue]
	13881160528 -> 13985217744
	13985217744 [label=AccumulateGrad]
	13985217648 -> 13985217600
	13985217648 [label=NativeBatchNormBackward0]
	13985218080 -> 13985217648
	13985218080 [label=ConvolutionBackward0]
	13985433392 -> 13985218080
	13985433392 [label=ReluBackward0]
	13985433872 -> 13985433392
	13985433872 [label=NativeBatchNormBackward0]
	13985433584 -> 13985433872
	13985433584 [label=ConvolutionBackward0]
	13985434064 -> 13985433584
	13985434064 [label=ReluBackward0]
	13985434208 -> 13985434064
	13985434208 [label=NativeBatchNormBackward0]
	13985434304 -> 13985434208
	13985434304 [label=ConvolutionBackward0]
	13985218032 -> 13985434304
	13985434496 -> 13985434304
	13881160912 [label="trunk_output.block2.block2-0.f.a.0.weight
 (192, 96, 1, 1)" fillcolor=lightblue]
	13881160912 -> 13985434496
	13985434496 [label=AccumulateGrad]
	13985434256 -> 13985434208
	13881161008 [label="trunk_output.block2.block2-0.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881161008 -> 13985434256
	13985434256 [label=AccumulateGrad]
	13985434112 -> 13985434208
	13881161104 [label="trunk_output.block2.block2-0.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881161104 -> 13985434112
	13985434112 [label=AccumulateGrad]
	13985433824 -> 13985433584
	13881161488 [label="trunk_output.block2.block2-0.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881161488 -> 13985433824
	13985433824 [label=AccumulateGrad]
	13985433776 -> 13985433872
	13881161584 [label="trunk_output.block2.block2-0.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881161584 -> 13985433776
	13985433776 [label=AccumulateGrad]
	13985433152 -> 13985433872
	13881161680 [label="trunk_output.block2.block2-0.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881161680 -> 13985433152
	13985433152 [label=AccumulateGrad]
	13985432720 -> 13985218080
	13881162064 [label="trunk_output.block2.block2-0.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881162064 -> 13985432720
	13985432720 [label=AccumulateGrad]
	13985217936 -> 13985217648
	13881162160 [label="trunk_output.block2.block2-0.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881162160 -> 13985217936
	13985217936 [label=AccumulateGrad]
	13985217888 -> 13985217648
	13881162256 [label="trunk_output.block2.block2-0.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881162256 -> 13985217888
	13985217888 [label=AccumulateGrad]
	13985217408 -> 13985217360
	13985217408 [label=NativeBatchNormBackward0]
	13985218128 -> 13985217408
	13985218128 [label=ConvolutionBackward0]
	13985433104 -> 13985218128
	13985433104 [label=ReluBackward0]
	13985434160 -> 13985433104
	13985434160 [label=NativeBatchNormBackward0]
	13985434544 -> 13985434160
	13985434544 [label=ConvolutionBackward0]
	13985434736 -> 13985434544
	13985434736 [label=ReluBackward0]
	13985434880 -> 13985434736
	13985434880 [label=NativeBatchNormBackward0]
	13985434976 -> 13985434880
	13985434976 [label=ConvolutionBackward0]
	13985217456 -> 13985434976
	13985435168 -> 13985434976
	13881162640 [label="trunk_output.block2.block2-1.f.a.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881162640 -> 13985435168
	13985435168 [label=AccumulateGrad]
	13985434928 -> 13985434880
	13881162736 [label="trunk_output.block2.block2-1.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881162736 -> 13985434928
	13985434928 [label=AccumulateGrad]
	13985434784 -> 13985434880
	13881162832 [label="trunk_output.block2.block2-1.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881162832 -> 13985434784
	13985434784 [label=AccumulateGrad]
	13985434688 -> 13985434544
	13881163216 [label="trunk_output.block2.block2-1.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881163216 -> 13985434688
	13985434688 [label=AccumulateGrad]
	13985434592 -> 13985434160
	13881163312 [label="trunk_output.block2.block2-1.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881163312 -> 13985434592
	13985434592 [label=AccumulateGrad]
	13985434448 -> 13985434160
	13881163408 [label="trunk_output.block2.block2-1.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881163408 -> 13985434448
	13985434448 [label=AccumulateGrad]
	13985434016 -> 13985218128
	13881393232 [label="trunk_output.block2.block2-1.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881393232 -> 13985434016
	13985434016 [label=AccumulateGrad]
	13985217504 -> 13985217408
	13881393328 [label="trunk_output.block2.block2-1.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881393328 -> 13985217504
	13985217504 [label=AccumulateGrad]
	13985217552 -> 13985217408
	13881393424 [label="trunk_output.block2.block2-1.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881393424 -> 13985217552
	13985217552 [label=AccumulateGrad]
	13985217168 -> 13985217120
	13985217168 [label=NativeBatchNormBackward0]
	13985217264 -> 13985217168
	13985217264 [label=ConvolutionBackward0]
	13985434352 -> 13985217264
	13985434352 [label=ReluBackward0]
	13985434832 -> 13985434352
	13985434832 [label=NativeBatchNormBackward0]
	13985435216 -> 13985434832
	13985435216 [label=ConvolutionBackward0]
	13985435408 -> 13985435216
	13985435408 [label=ReluBackward0]
	13985435552 -> 13985435408
	13985435552 [label=NativeBatchNormBackward0]
	13985435648 -> 13985435552
	13985435648 [label=ConvolutionBackward0]
	13985217216 -> 13985435648
	13985435840 -> 13985435648
	13881393808 [label="trunk_output.block2.block2-2.f.a.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881393808 -> 13985435840
	13985435840 [label=AccumulateGrad]
	13985435600 -> 13985435552
	13881393904 [label="trunk_output.block2.block2-2.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881393904 -> 13985435600
	13985435600 [label=AccumulateGrad]
	13985435456 -> 13985435552
	13881394000 [label="trunk_output.block2.block2-2.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881394000 -> 13985435456
	13985435456 [label=AccumulateGrad]
	13985435360 -> 13985435216
	13881394384 [label="trunk_output.block2.block2-2.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881394384 -> 13985435360
	13985435360 [label=AccumulateGrad]
	13985435264 -> 13985434832
	13881394480 [label="trunk_output.block2.block2-2.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881394480 -> 13985435264
	13985435264 [label=AccumulateGrad]
	13985435120 -> 13985434832
	13881394576 [label="trunk_output.block2.block2-2.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881394576 -> 13985435120
	13985435120 [label=AccumulateGrad]
	13985434400 -> 13985217264
	13881394960 [label="trunk_output.block2.block2-2.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881394960 -> 13985434400
	13985434400 [label=AccumulateGrad]
	13985217312 -> 13985217168
	13881395056 [label="trunk_output.block2.block2-2.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881395056 -> 13985217312
	13985217312 [label=AccumulateGrad]
	13985432000 -> 13985217168
	13881395152 [label="trunk_output.block2.block2-2.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881395152 -> 13985432000
	13985432000 [label=AccumulateGrad]
	13985216928 -> 13985216880
	13985216928 [label=NativeBatchNormBackward0]
	13985217024 -> 13985216928
	13985217024 [label=ConvolutionBackward0]
	13985435024 -> 13985217024
	13985435024 [label=ReluBackward0]
	13985435504 -> 13985435024
	13985435504 [label=NativeBatchNormBackward0]
	13985435888 -> 13985435504
	13985435888 [label=ConvolutionBackward0]
	13985436080 -> 13985435888
	13985436080 [label=ReluBackward0]
	13985436224 -> 13985436080
	13985436224 [label=NativeBatchNormBackward0]
	13985436320 -> 13985436224
	13985436320 [label=ConvolutionBackward0]
	13985216976 -> 13985436320
	13985436512 -> 13985436320
	13881395536 [label="trunk_output.block2.block2-3.f.a.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881395536 -> 13985436512
	13985436512 [label=AccumulateGrad]
	13985436272 -> 13985436224
	13881395632 [label="trunk_output.block2.block2-3.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881395632 -> 13985436272
	13985436272 [label=AccumulateGrad]
	13985436128 -> 13985436224
	13881395728 [label="trunk_output.block2.block2-3.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881395728 -> 13985436128
	13985436128 [label=AccumulateGrad]
	13985436032 -> 13985435888
	13881396112 [label="trunk_output.block2.block2-3.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881396112 -> 13985436032
	13985436032 [label=AccumulateGrad]
	13985435936 -> 13985435504
	13881396208 [label="trunk_output.block2.block2-3.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881396208 -> 13985435936
	13985435936 [label=AccumulateGrad]
	13985435792 -> 13985435504
	13881396304 [label="trunk_output.block2.block2-3.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881396304 -> 13985435792
	13985435792 [label=AccumulateGrad]
	13985435072 -> 13985217024
	13881396688 [label="trunk_output.block2.block2-3.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881396688 -> 13985435072
	13985435072 [label=AccumulateGrad]
	13985217072 -> 13985216928
	13881396784 [label="trunk_output.block2.block2-3.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881396784 -> 13985217072
	13985217072 [label=AccumulateGrad]
	13985433968 -> 13985216928
	13881396880 [label="trunk_output.block2.block2-3.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881396880 -> 13985433968
	13985433968 [label=AccumulateGrad]
	13985216688 -> 13985216640
	13985216688 [label=NativeBatchNormBackward0]
	13985216784 -> 13985216688
	13985216784 [label=ConvolutionBackward0]
	13985435696 -> 13985216784
	13985435696 [label=ReluBackward0]
	13985436176 -> 13985435696
	13985436176 [label=NativeBatchNormBackward0]
	13985436560 -> 13985436176
	13985436560 [label=ConvolutionBackward0]
	13985436752 -> 13985436560
	13985436752 [label=ReluBackward0]
	13985436896 -> 13985436752
	13985436896 [label=NativeBatchNormBackward0]
	13985436992 -> 13985436896
	13985436992 [label=ConvolutionBackward0]
	13985216736 -> 13985436992
	13985437184 -> 13985436992
	13881397264 [label="trunk_output.block2.block2-4.f.a.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881397264 -> 13985437184
	13985437184 [label=AccumulateGrad]
	13985436944 -> 13985436896
	13881397360 [label="trunk_output.block2.block2-4.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881397360 -> 13985436944
	13985436944 [label=AccumulateGrad]
	13985436800 -> 13985436896
	13881397456 [label="trunk_output.block2.block2-4.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881397456 -> 13985436800
	13985436800 [label=AccumulateGrad]
	13985436704 -> 13985436560
	13881397840 [label="trunk_output.block2.block2-4.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881397840 -> 13985436704
	13985436704 [label=AccumulateGrad]
	13985436608 -> 13985436176
	13881397936 [label="trunk_output.block2.block2-4.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881397936 -> 13985436608
	13985436608 [label=AccumulateGrad]
	13985436464 -> 13985436176
	13881398032 [label="trunk_output.block2.block2-4.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881398032 -> 13985436464
	13985436464 [label=AccumulateGrad]
	13985435744 -> 13985216784
	13881398416 [label="trunk_output.block2.block2-4.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881398416 -> 13985435744
	13985435744 [label=AccumulateGrad]
	13985216832 -> 13985216688
	13881398512 [label="trunk_output.block2.block2-4.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881398512 -> 13985216832
	13985216832 [label=AccumulateGrad]
	13985434640 -> 13985216688
	13881398608 [label="trunk_output.block2.block2-4.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881398608 -> 13985434640
	13985434640 [label=AccumulateGrad]
	13985216448 -> 13985216400
	13985216448 [label=NativeBatchNormBackward0]
	13985216544 -> 13985216448
	13985216544 [label=ConvolutionBackward0]
	13985436368 -> 13985216544
	13985436368 [label=ReluBackward0]
	13985436848 -> 13985436368
	13985436848 [label=NativeBatchNormBackward0]
	13985437232 -> 13985436848
	13985437232 [label=ConvolutionBackward0]
	13985437424 -> 13985437232
	13985437424 [label=ReluBackward0]
	13985437568 -> 13985437424
	13985437568 [label=NativeBatchNormBackward0]
	13985437664 -> 13985437568
	13985437664 [label=ConvolutionBackward0]
	13985216496 -> 13985437664
	13985437856 -> 13985437664
	13881398992 [label="trunk_output.block2.block2-5.f.a.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881398992 -> 13985437856
	13985437856 [label=AccumulateGrad]
	13985437616 -> 13985437568
	13881399088 [label="trunk_output.block2.block2-5.f.a.1.weight
 (192)" fillcolor=lightblue]
	13881399088 -> 13985437616
	13985437616 [label=AccumulateGrad]
	13985437472 -> 13985437568
	13881399184 [label="trunk_output.block2.block2-5.f.a.1.bias
 (192)" fillcolor=lightblue]
	13881399184 -> 13985437472
	13985437472 [label=AccumulateGrad]
	13985437376 -> 13985437232
	13881399568 [label="trunk_output.block2.block2-5.f.b.0.weight
 (192, 48, 3, 3)" fillcolor=lightblue]
	13881399568 -> 13985437376
	13985437376 [label=AccumulateGrad]
	13985437280 -> 13985436848
	13881399664 [label="trunk_output.block2.block2-5.f.b.1.weight
 (192)" fillcolor=lightblue]
	13881399664 -> 13985437280
	13985437280 [label=AccumulateGrad]
	13985437136 -> 13985436848
	13881399760 [label="trunk_output.block2.block2-5.f.b.1.bias
 (192)" fillcolor=lightblue]
	13881399760 -> 13985437136
	13985437136 [label=AccumulateGrad]
	13985436416 -> 13985216544
	13881400144 [label="trunk_output.block2.block2-5.f.c.0.weight
 (192, 192, 1, 1)" fillcolor=lightblue]
	13881400144 -> 13985436416
	13985436416 [label=AccumulateGrad]
	13985216592 -> 13985216448
	13881400240 [label="trunk_output.block2.block2-5.f.c.1.weight
 (192)" fillcolor=lightblue]
	13881400240 -> 13985216592
	13985216592 [label=AccumulateGrad]
	13985435312 -> 13985216448
	13881400336 [label="trunk_output.block2.block2-5.f.c.1.bias
 (192)" fillcolor=lightblue]
	13881400336 -> 13985435312
	13985435312 [label=AccumulateGrad]
	13985216208 -> 13985216064
	13881400720 [label="trunk_output.block3.block3-0.proj.0.weight
 (432, 192, 1, 1)" fillcolor=lightblue]
	13881400720 -> 13985216208
	13985216208 [label=AccumulateGrad]
	13985216016 -> 13985215920
	13881400816 [label="trunk_output.block3.block3-0.proj.1.weight
 (432)" fillcolor=lightblue]
	13881400816 -> 13985216016
	13985216016 [label=AccumulateGrad]
	13985215968 -> 13985215920
	13881400912 [label="trunk_output.block3.block3-0.proj.1.bias
 (432)" fillcolor=lightblue]
	13881400912 -> 13985215968
	13985215968 [label=AccumulateGrad]
	13985215872 -> 13985215824
	13985215872 [label=NativeBatchNormBackward0]
	13985216304 -> 13985215872
	13985216304 [label=ConvolutionBackward0]
	13985437328 -> 13985216304
	13985437328 [label=ReluBackward0]
	13985437808 -> 13985437328
	13985437808 [label=NativeBatchNormBackward0]
	13985437520 -> 13985437808
	13985437520 [label=ConvolutionBackward0]
	13985438000 -> 13985437520
	13985438000 [label=ReluBackward0]
	13985438144 -> 13985438000
	13985438144 [label=NativeBatchNormBackward0]
	13985438240 -> 13985438144
	13985438240 [label=ConvolutionBackward0]
	13985216256 -> 13985438240
	13985438432 -> 13985438240
	13881401296 [label="trunk_output.block3.block3-0.f.a.0.weight
 (432, 192, 1, 1)" fillcolor=lightblue]
	13881401296 -> 13985438432
	13985438432 [label=AccumulateGrad]
	13985438192 -> 13985438144
	13881401392 [label="trunk_output.block3.block3-0.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881401392 -> 13985438192
	13985438192 [label=AccumulateGrad]
	13985438048 -> 13985438144
	13881401488 [label="trunk_output.block3.block3-0.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881401488 -> 13985438048
	13985438048 [label=AccumulateGrad]
	13985437760 -> 13985437520
	13881401872 [label="trunk_output.block3.block3-0.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881401872 -> 13985437760
	13985437760 [label=AccumulateGrad]
	13985437712 -> 13985437808
	13881401968 [label="trunk_output.block3.block3-0.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881401968 -> 13985437712
	13985437712 [label=AccumulateGrad]
	13985437088 -> 13985437808
	13881402064 [label="trunk_output.block3.block3-0.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881402064 -> 13985437088
	13985437088 [label=AccumulateGrad]
	13985436656 -> 13985216304
	13881402448 [label="trunk_output.block3.block3-0.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881402448 -> 13985436656
	13985436656 [label=AccumulateGrad]
	13985216160 -> 13985215872
	13881402544 [label="trunk_output.block3.block3-0.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881402544 -> 13985216160
	13985216160 [label=AccumulateGrad]
	13985216112 -> 13985215872
	13881402640 [label="trunk_output.block3.block3-0.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881402640 -> 13985216112
	13985216112 [label=AccumulateGrad]
	13985215632 -> 13985215584
	13985215632 [label=NativeBatchNormBackward0]
	13985216352 -> 13985215632
	13985216352 [label=ConvolutionBackward0]
	13985437040 -> 13985216352
	13985437040 [label=ReluBackward0]
	13985438096 -> 13985437040
	13985438096 [label=NativeBatchNormBackward0]
	13985438480 -> 13985438096
	13985438480 [label=ConvolutionBackward0]
	13985438672 -> 13985438480
	13985438672 [label=ReluBackward0]
	13985438816 -> 13985438672
	13985438816 [label=NativeBatchNormBackward0]
	13985438912 -> 13985438816
	13985438912 [label=ConvolutionBackward0]
	13985215680 -> 13985438912
	13985439104 -> 13985438912
	13881403024 [label="trunk_output.block3.block3-1.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881403024 -> 13985439104
	13985439104 [label=AccumulateGrad]
	13985438864 -> 13985438816
	13881403120 [label="trunk_output.block3.block3-1.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881403120 -> 13985438864
	13985438864 [label=AccumulateGrad]
	13985438720 -> 13985438816
	13881403216 [label="trunk_output.block3.block3-1.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881403216 -> 13985438720
	13985438720 [label=AccumulateGrad]
	13985438624 -> 13985438480
	13881403600 [label="trunk_output.block3.block3-1.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881403600 -> 13985438624
	13985438624 [label=AccumulateGrad]
	13985438528 -> 13985438096
	13881403696 [label="trunk_output.block3.block3-1.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881403696 -> 13985438528
	13985438528 [label=AccumulateGrad]
	13985438384 -> 13985438096
	13881403792 [label="trunk_output.block3.block3-1.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881403792 -> 13985438384
	13985438384 [label=AccumulateGrad]
	13985437952 -> 13985216352
	13881404176 [label="trunk_output.block3.block3-1.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881404176 -> 13985437952
	13985437952 [label=AccumulateGrad]
	13985215728 -> 13985215632
	13881404272 [label="trunk_output.block3.block3-1.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881404272 -> 13985215728
	13985215728 [label=AccumulateGrad]
	13985215776 -> 13985215632
	13881404368 [label="trunk_output.block3.block3-1.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881404368 -> 13985215776
	13985215776 [label=AccumulateGrad]
	13985215392 -> 13985215344
	13985215392 [label=NativeBatchNormBackward0]
	13985215488 -> 13985215392
	13985215488 [label=ConvolutionBackward0]
	13985438288 -> 13985215488
	13985438288 [label=ReluBackward0]
	13985438768 -> 13985438288
	13985438768 [label=NativeBatchNormBackward0]
	13985439152 -> 13985438768
	13985439152 [label=ConvolutionBackward0]
	13985439344 -> 13985439152
	13985439344 [label=ReluBackward0]
	13985439488 -> 13985439344
	13985439488 [label=NativeBatchNormBackward0]
	13985439584 -> 13985439488
	13985439584 [label=ConvolutionBackward0]
	13985215440 -> 13985439584
	13985439776 -> 13985439584
	13881404752 [label="trunk_output.block3.block3-2.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881404752 -> 13985439776
	13985439776 [label=AccumulateGrad]
	13985439536 -> 13985439488
	13881404848 [label="trunk_output.block3.block3-2.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881404848 -> 13985439536
	13985439536 [label=AccumulateGrad]
	13985439392 -> 13985439488
	13881404944 [label="trunk_output.block3.block3-2.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881404944 -> 13985439392
	13985439392 [label=AccumulateGrad]
	13985439296 -> 13985439152
	13881405328 [label="trunk_output.block3.block3-2.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881405328 -> 13985439296
	13985439296 [label=AccumulateGrad]
	13985439200 -> 13985438768
	13881405424 [label="trunk_output.block3.block3-2.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881405424 -> 13985439200
	13985439200 [label=AccumulateGrad]
	13985439056 -> 13985438768
	13881405520 [label="trunk_output.block3.block3-2.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881405520 -> 13985439056
	13985439056 [label=AccumulateGrad]
	13985438336 -> 13985215488
	13881405904 [label="trunk_output.block3.block3-2.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881405904 -> 13985438336
	13985438336 [label=AccumulateGrad]
	13985215536 -> 13985215392
	13881406000 [label="trunk_output.block3.block3-2.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881406000 -> 13985215536
	13985215536 [label=AccumulateGrad]
	13985435984 -> 13985215392
	13881406096 [label="trunk_output.block3.block3-2.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881406096 -> 13985435984
	13985435984 [label=AccumulateGrad]
	13985215152 -> 13985215104
	13985215152 [label=NativeBatchNormBackward0]
	13985215248 -> 13985215152
	13985215248 [label=ConvolutionBackward0]
	13985438960 -> 13985215248
	13985438960 [label=ReluBackward0]
	13985439440 -> 13985438960
	13985439440 [label=NativeBatchNormBackward0]
	13985439824 -> 13985439440
	13985439824 [label=ConvolutionBackward0]
	13985440016 -> 13985439824
	13985440016 [label=ReluBackward0]
	13985440160 -> 13985440016
	13985440160 [label=NativeBatchNormBackward0]
	13985440256 -> 13985440160
	13985440256 [label=ConvolutionBackward0]
	13985215200 -> 13985440256
	13985440448 -> 13985440256
	13881406480 [label="trunk_output.block3.block3-3.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881406480 -> 13985440448
	13985440448 [label=AccumulateGrad]
	13985440208 -> 13985440160
	13881406576 [label="trunk_output.block3.block3-3.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881406576 -> 13985440208
	13985440208 [label=AccumulateGrad]
	13985440064 -> 13985440160
	13881406672 [label="trunk_output.block3.block3-3.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881406672 -> 13985440064
	13985440064 [label=AccumulateGrad]
	13985439968 -> 13985439824
	13881407056 [label="trunk_output.block3.block3-3.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881407056 -> 13985439968
	13985439968 [label=AccumulateGrad]
	13985439872 -> 13985439440
	13881407152 [label="trunk_output.block3.block3-3.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881407152 -> 13985439872
	13985439872 [label=AccumulateGrad]
	13985439728 -> 13985439440
	13881407248 [label="trunk_output.block3.block3-3.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881407248 -> 13985439728
	13985439728 [label=AccumulateGrad]
	13985439008 -> 13985215248
	13881407632 [label="trunk_output.block3.block3-3.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881407632 -> 13985439008
	13985439008 [label=AccumulateGrad]
	13985215296 -> 13985215152
	13881407728 [label="trunk_output.block3.block3-3.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881407728 -> 13985215296
	13985215296 [label=AccumulateGrad]
	13985437904 -> 13985215152
	13881407824 [label="trunk_output.block3.block3-3.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881407824 -> 13985437904
	13985437904 [label=AccumulateGrad]
	13985214912 -> 13985214864
	13985214912 [label=NativeBatchNormBackward0]
	13985215008 -> 13985214912
	13985215008 [label=ConvolutionBackward0]
	13985439632 -> 13985215008
	13985439632 [label=ReluBackward0]
	13985440112 -> 13985439632
	13985440112 [label=NativeBatchNormBackward0]
	13985440496 -> 13985440112
	13985440496 [label=ConvolutionBackward0]
	13985440688 -> 13985440496
	13985440688 [label=ReluBackward0]
	13985440832 -> 13985440688
	13985440832 [label=NativeBatchNormBackward0]
	13985440928 -> 13985440832
	13985440928 [label=ConvolutionBackward0]
	13985214960 -> 13985440928
	13985441120 -> 13985440928
	13881408208 [label="trunk_output.block3.block3-4.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881408208 -> 13985441120
	13985441120 [label=AccumulateGrad]
	13985440880 -> 13985440832
	13881408304 [label="trunk_output.block3.block3-4.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881408304 -> 13985440880
	13985440880 [label=AccumulateGrad]
	13985440736 -> 13985440832
	13881408400 [label="trunk_output.block3.block3-4.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881408400 -> 13985440736
	13985440736 [label=AccumulateGrad]
	13985440640 -> 13985440496
	13881408784 [label="trunk_output.block3.block3-4.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881408784 -> 13985440640
	13985440640 [label=AccumulateGrad]
	13985440544 -> 13985440112
	13881408880 [label="trunk_output.block3.block3-4.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881408880 -> 13985440544
	13985440544 [label=AccumulateGrad]
	13985440400 -> 13985440112
	13881408976 [label="trunk_output.block3.block3-4.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881408976 -> 13985440400
	13985440400 [label=AccumulateGrad]
	13985439680 -> 13985215008
	13881409360 [label="trunk_output.block3.block3-4.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881409360 -> 13985439680
	13985439680 [label=AccumulateGrad]
	13985215056 -> 13985214912
	13881409456 [label="trunk_output.block3.block3-4.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881409456 -> 13985215056
	13985215056 [label=AccumulateGrad]
	13985438576 -> 13985214912
	13881737296 [label="trunk_output.block3.block3-4.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881737296 -> 13985438576
	13985438576 [label=AccumulateGrad]
	13985214672 -> 13985214624
	13985214672 [label=NativeBatchNormBackward0]
	13985214768 -> 13985214672
	13985214768 [label=ConvolutionBackward0]
	13985440304 -> 13985214768
	13985440304 [label=ReluBackward0]
	13985440784 -> 13985440304
	13985440784 [label=NativeBatchNormBackward0]
	13985441168 -> 13985440784
	13985441168 [label=ConvolutionBackward0]
	13985441360 -> 13985441168
	13985441360 [label=ReluBackward0]
	13985441504 -> 13985441360
	13985441504 [label=NativeBatchNormBackward0]
	13985441600 -> 13985441504
	13985441600 [label=ConvolutionBackward0]
	13985214720 -> 13985441600
	13985441792 -> 13985441600
	13881737680 [label="trunk_output.block3.block3-5.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881737680 -> 13985441792
	13985441792 [label=AccumulateGrad]
	13985441552 -> 13985441504
	13881737776 [label="trunk_output.block3.block3-5.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881737776 -> 13985441552
	13985441552 [label=AccumulateGrad]
	13985441408 -> 13985441504
	13881737872 [label="trunk_output.block3.block3-5.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881737872 -> 13985441408
	13985441408 [label=AccumulateGrad]
	13985441312 -> 13985441168
	13881738256 [label="trunk_output.block3.block3-5.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881738256 -> 13985441312
	13985441312 [label=AccumulateGrad]
	13985441216 -> 13985440784
	13881738352 [label="trunk_output.block3.block3-5.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881738352 -> 13985441216
	13985441216 [label=AccumulateGrad]
	13985441072 -> 13985440784
	13881738448 [label="trunk_output.block3.block3-5.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881738448 -> 13985441072
	13985441072 [label=AccumulateGrad]
	13985440352 -> 13985214768
	13881738832 [label="trunk_output.block3.block3-5.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881738832 -> 13985440352
	13985440352 [label=AccumulateGrad]
	13985214816 -> 13985214672
	13881738928 [label="trunk_output.block3.block3-5.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881738928 -> 13985214816
	13985214816 [label=AccumulateGrad]
	13985439248 -> 13985214672
	13881739024 [label="trunk_output.block3.block3-5.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881739024 -> 13985439248
	13985439248 [label=AccumulateGrad]
	13985214432 -> 13985214384
	13985214432 [label=NativeBatchNormBackward0]
	13985214528 -> 13985214432
	13985214528 [label=ConvolutionBackward0]
	13985440976 -> 13985214528
	13985440976 [label=ReluBackward0]
	13985441456 -> 13985440976
	13985441456 [label=NativeBatchNormBackward0]
	13985441840 -> 13985441456
	13985441840 [label=ConvolutionBackward0]
	13985442032 -> 13985441840
	13985442032 [label=ReluBackward0]
	13985442176 -> 13985442032
	13985442176 [label=NativeBatchNormBackward0]
	13985442272 -> 13985442176
	13985442272 [label=ConvolutionBackward0]
	13985214480 -> 13985442272
	13985442464 -> 13985442272
	13881739408 [label="trunk_output.block3.block3-6.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881739408 -> 13985442464
	13985442464 [label=AccumulateGrad]
	13985442224 -> 13985442176
	13881739504 [label="trunk_output.block3.block3-6.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881739504 -> 13985442224
	13985442224 [label=AccumulateGrad]
	13985442080 -> 13985442176
	13881739600 [label="trunk_output.block3.block3-6.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881739600 -> 13985442080
	13985442080 [label=AccumulateGrad]
	13985441984 -> 13985441840
	13881739984 [label="trunk_output.block3.block3-6.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881739984 -> 13985441984
	13985441984 [label=AccumulateGrad]
	13985441888 -> 13985441456
	13881740080 [label="trunk_output.block3.block3-6.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881740080 -> 13985441888
	13985441888 [label=AccumulateGrad]
	13985441744 -> 13985441456
	13881740176 [label="trunk_output.block3.block3-6.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881740176 -> 13985441744
	13985441744 [label=AccumulateGrad]
	13985441024 -> 13985214528
	13881740560 [label="trunk_output.block3.block3-6.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881740560 -> 13985441024
	13985441024 [label=AccumulateGrad]
	13985214576 -> 13985214432
	13881740656 [label="trunk_output.block3.block3-6.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881740656 -> 13985214576
	13985214576 [label=AccumulateGrad]
	13985439920 -> 13985214432
	13881740752 [label="trunk_output.block3.block3-6.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881740752 -> 13985439920
	13985439920 [label=AccumulateGrad]
	13985214192 -> 13985214144
	13985214192 [label=NativeBatchNormBackward0]
	13985214288 -> 13985214192
	13985214288 [label=ConvolutionBackward0]
	13985441648 -> 13985214288
	13985441648 [label=ReluBackward0]
	13985442128 -> 13985441648
	13985442128 [label=NativeBatchNormBackward0]
	13985442512 -> 13985442128
	13985442512 [label=ConvolutionBackward0]
	13985442704 -> 13985442512
	13985442704 [label=ReluBackward0]
	13985442848 -> 13985442704
	13985442848 [label=NativeBatchNormBackward0]
	13985442944 -> 13985442848
	13985442944 [label=ConvolutionBackward0]
	13985214240 -> 13985442944
	13985443136 -> 13985442944
	13881741136 [label="trunk_output.block3.block3-7.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881741136 -> 13985443136
	13985443136 [label=AccumulateGrad]
	13985442896 -> 13985442848
	13881741232 [label="trunk_output.block3.block3-7.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881741232 -> 13985442896
	13985442896 [label=AccumulateGrad]
	13985442752 -> 13985442848
	13881741328 [label="trunk_output.block3.block3-7.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881741328 -> 13985442752
	13985442752 [label=AccumulateGrad]
	13985442656 -> 13985442512
	13881741712 [label="trunk_output.block3.block3-7.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881741712 -> 13985442656
	13985442656 [label=AccumulateGrad]
	13985442560 -> 13985442128
	13881741808 [label="trunk_output.block3.block3-7.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881741808 -> 13985442560
	13985442560 [label=AccumulateGrad]
	13985442416 -> 13985442128
	13881741904 [label="trunk_output.block3.block3-7.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881741904 -> 13985442416
	13985442416 [label=AccumulateGrad]
	13985441696 -> 13985214288
	13881742288 [label="trunk_output.block3.block3-7.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881742288 -> 13985441696
	13985441696 [label=AccumulateGrad]
	13985214336 -> 13985214192
	13881742384 [label="trunk_output.block3.block3-7.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881742384 -> 13985214336
	13985214336 [label=AccumulateGrad]
	13985440592 -> 13985214192
	13881742480 [label="trunk_output.block3.block3-7.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881742480 -> 13985440592
	13985440592 [label=AccumulateGrad]
	13985213952 -> 13985213904
	13985213952 [label=NativeBatchNormBackward0]
	13985214048 -> 13985213952
	13985214048 [label=ConvolutionBackward0]
	13985442320 -> 13985214048
	13985442320 [label=ReluBackward0]
	13985442800 -> 13985442320
	13985442800 [label=NativeBatchNormBackward0]
	13985443184 -> 13985442800
	13985443184 [label=ConvolutionBackward0]
	13985443376 -> 13985443184
	13985443376 [label=ReluBackward0]
	13985443520 -> 13985443376
	13985443520 [label=NativeBatchNormBackward0]
	13985443616 -> 13985443520
	13985443616 [label=ConvolutionBackward0]
	13985214000 -> 13985443616
	13985443808 -> 13985443616
	13881742864 [label="trunk_output.block3.block3-8.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881742864 -> 13985443808
	13985443808 [label=AccumulateGrad]
	13985443568 -> 13985443520
	13881742960 [label="trunk_output.block3.block3-8.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881742960 -> 13985443568
	13985443568 [label=AccumulateGrad]
	13985443424 -> 13985443520
	13881743056 [label="trunk_output.block3.block3-8.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881743056 -> 13985443424
	13985443424 [label=AccumulateGrad]
	13985443328 -> 13985443184
	13881743440 [label="trunk_output.block3.block3-8.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881743440 -> 13985443328
	13985443328 [label=AccumulateGrad]
	13985443232 -> 13985442800
	13881743536 [label="trunk_output.block3.block3-8.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881743536 -> 13985443232
	13985443232 [label=AccumulateGrad]
	13985443088 -> 13985442800
	13881743632 [label="trunk_output.block3.block3-8.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881743632 -> 13985443088
	13985443088 [label=AccumulateGrad]
	13985442368 -> 13985214048
	13881744016 [label="trunk_output.block3.block3-8.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881744016 -> 13985442368
	13985442368 [label=AccumulateGrad]
	13985214096 -> 13985213952
	13881744112 [label="trunk_output.block3.block3-8.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881744112 -> 13985214096
	13985214096 [label=AccumulateGrad]
	13985441264 -> 13985213952
	13881744208 [label="trunk_output.block3.block3-8.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881744208 -> 13985441264
	13985441264 [label=AccumulateGrad]
	13985213712 -> 13985213664
	13985213712 [label=NativeBatchNormBackward0]
	13985213808 -> 13985213712
	13985213808 [label=ConvolutionBackward0]
	13985442992 -> 13985213808
	13985442992 [label=ReluBackward0]
	13985443472 -> 13985442992
	13985443472 [label=NativeBatchNormBackward0]
	13985443856 -> 13985443472
	13985443856 [label=ConvolutionBackward0]
	13985444048 -> 13985443856
	13985444048 [label=ReluBackward0]
	13985444192 -> 13985444048
	13985444192 [label=NativeBatchNormBackward0]
	13985444288 -> 13985444192
	13985444288 [label=ConvolutionBackward0]
	13985213760 -> 13985444288
	13985444480 -> 13985444288
	13881744592 [label="trunk_output.block3.block3-9.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881744592 -> 13985444480
	13985444480 [label=AccumulateGrad]
	13985444240 -> 13985444192
	13881744688 [label="trunk_output.block3.block3-9.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881744688 -> 13985444240
	13985444240 [label=AccumulateGrad]
	13985444096 -> 13985444192
	13881744784 [label="trunk_output.block3.block3-9.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881744784 -> 13985444096
	13985444096 [label=AccumulateGrad]
	13985444000 -> 13985443856
	13881745168 [label="trunk_output.block3.block3-9.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881745168 -> 13985444000
	13985444000 [label=AccumulateGrad]
	13985443904 -> 13985443472
	13881745264 [label="trunk_output.block3.block3-9.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881745264 -> 13985443904
	13985443904 [label=AccumulateGrad]
	13985443760 -> 13985443472
	13881745360 [label="trunk_output.block3.block3-9.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881745360 -> 13985443760
	13985443760 [label=AccumulateGrad]
	13985443040 -> 13985213808
	13881745744 [label="trunk_output.block3.block3-9.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881745744 -> 13985443040
	13985443040 [label=AccumulateGrad]
	13985213856 -> 13985213712
	13881745840 [label="trunk_output.block3.block3-9.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881745840 -> 13985213856
	13985213856 [label=AccumulateGrad]
	13985441936 -> 13985213712
	13881745936 [label="trunk_output.block3.block3-9.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881745936 -> 13985441936
	13985441936 [label=AccumulateGrad]
	13985213472 -> 13985213424
	13985213472 [label=NativeBatchNormBackward0]
	13985213568 -> 13985213472
	13985213568 [label=ConvolutionBackward0]
	13985443664 -> 13985213568
	13985443664 [label=ReluBackward0]
	13985444144 -> 13985443664
	13985444144 [label=NativeBatchNormBackward0]
	13985444528 -> 13985444144
	13985444528 [label=ConvolutionBackward0]
	13985444720 -> 13985444528
	13985444720 [label=ReluBackward0]
	13985444864 -> 13985444720
	13985444864 [label=NativeBatchNormBackward0]
	13985444960 -> 13985444864
	13985444960 [label=ConvolutionBackward0]
	13985213520 -> 13985444960
	13985445152 -> 13985444960
	13881746320 [label="trunk_output.block3.block3-10.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881746320 -> 13985445152
	13985445152 [label=AccumulateGrad]
	13985444912 -> 13985444864
	13881746416 [label="trunk_output.block3.block3-10.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881746416 -> 13985444912
	13985444912 [label=AccumulateGrad]
	13985444768 -> 13985444864
	13881746512 [label="trunk_output.block3.block3-10.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881746512 -> 13985444768
	13985444768 [label=AccumulateGrad]
	13985444672 -> 13985444528
	13881746896 [label="trunk_output.block3.block3-10.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881746896 -> 13985444672
	13985444672 [label=AccumulateGrad]
	13985444576 -> 13985444144
	13881746992 [label="trunk_output.block3.block3-10.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881746992 -> 13985444576
	13985444576 [label=AccumulateGrad]
	13985444432 -> 13985444144
	13881747088 [label="trunk_output.block3.block3-10.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881747088 -> 13985444432
	13985444432 [label=AccumulateGrad]
	13985443712 -> 13985213568
	13881747472 [label="trunk_output.block3.block3-10.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881747472 -> 13985443712
	13985443712 [label=AccumulateGrad]
	13985213616 -> 13985213472
	13881747568 [label="trunk_output.block3.block3-10.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881747568 -> 13985213616
	13985213616 [label=AccumulateGrad]
	13985442608 -> 13985213472
	13881747664 [label="trunk_output.block3.block3-10.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881747664 -> 13985442608
	13985442608 [label=AccumulateGrad]
	13985213232 -> 13985213184
	13985213232 [label=NativeBatchNormBackward0]
	13985213328 -> 13985213232
	13985213328 [label=ConvolutionBackward0]
	13985444336 -> 13985213328
	13985444336 [label=ReluBackward0]
	13985444816 -> 13985444336
	13985444816 [label=NativeBatchNormBackward0]
	13985445200 -> 13985444816
	13985445200 [label=ConvolutionBackward0]
	13985445392 -> 13985445200
	13985445392 [label=ReluBackward0]
	13985445536 -> 13985445392
	13985445536 [label=NativeBatchNormBackward0]
	13985445632 -> 13985445536
	13985445632 [label=ConvolutionBackward0]
	13985213280 -> 13985445632
	13985445824 -> 13985445632
	13881748048 [label="trunk_output.block3.block3-11.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881748048 -> 13985445824
	13985445824 [label=AccumulateGrad]
	13985445584 -> 13985445536
	13881748144 [label="trunk_output.block3.block3-11.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881748144 -> 13985445584
	13985445584 [label=AccumulateGrad]
	13985445440 -> 13985445536
	13881748240 [label="trunk_output.block3.block3-11.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881748240 -> 13985445440
	13985445440 [label=AccumulateGrad]
	13985445344 -> 13985445200
	13881748624 [label="trunk_output.block3.block3-11.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881748624 -> 13985445344
	13985445344 [label=AccumulateGrad]
	13985445248 -> 13985444816
	13881748720 [label="trunk_output.block3.block3-11.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881748720 -> 13985445248
	13985445248 [label=AccumulateGrad]
	13985445104 -> 13985444816
	13881748816 [label="trunk_output.block3.block3-11.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881748816 -> 13985445104
	13985445104 [label=AccumulateGrad]
	13985444384 -> 13985213328
	13881749200 [label="trunk_output.block3.block3-11.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881749200 -> 13985444384
	13985444384 [label=AccumulateGrad]
	13985213376 -> 13985213232
	13881749296 [label="trunk_output.block3.block3-11.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881749296 -> 13985213376
	13985213376 [label=AccumulateGrad]
	13985443280 -> 13985213232
	13881749392 [label="trunk_output.block3.block3-11.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881749392 -> 13985443280
	13985443280 [label=AccumulateGrad]
	13985212992 -> 13985212944
	13985212992 [label=NativeBatchNormBackward0]
	13985213088 -> 13985212992
	13985213088 [label=ConvolutionBackward0]
	13985445008 -> 13985213088
	13985445008 [label=ReluBackward0]
	13985445488 -> 13985445008
	13985445488 [label=NativeBatchNormBackward0]
	13985445872 -> 13985445488
	13985445872 [label=ConvolutionBackward0]
	13985446064 -> 13985445872
	13985446064 [label=ReluBackward0]
	13985446208 -> 13985446064
	13985446208 [label=NativeBatchNormBackward0]
	13985446304 -> 13985446208
	13985446304 [label=ConvolutionBackward0]
	13985213040 -> 13985446304
	13985446496 -> 13985446304
	13881749776 [label="trunk_output.block3.block3-12.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881749776 -> 13985446496
	13985446496 [label=AccumulateGrad]
	13985446256 -> 13985446208
	13881749872 [label="trunk_output.block3.block3-12.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881749872 -> 13985446256
	13985446256 [label=AccumulateGrad]
	13985446112 -> 13985446208
	13881749968 [label="trunk_output.block3.block3-12.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881749968 -> 13985446112
	13985446112 [label=AccumulateGrad]
	13985446016 -> 13985445872
	13881750352 [label="trunk_output.block3.block3-12.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881750352 -> 13985446016
	13985446016 [label=AccumulateGrad]
	13985445920 -> 13985445488
	13881750448 [label="trunk_output.block3.block3-12.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881750448 -> 13985445920
	13985445920 [label=AccumulateGrad]
	13985445776 -> 13985445488
	13881750544 [label="trunk_output.block3.block3-12.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881750544 -> 13985445776
	13985445776 [label=AccumulateGrad]
	13985445056 -> 13985213088
	13881750928 [label="trunk_output.block3.block3-12.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881750928 -> 13985445056
	13985445056 [label=AccumulateGrad]
	13985213136 -> 13985212992
	13881751024 [label="trunk_output.block3.block3-12.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881751024 -> 13985213136
	13985213136 [label=AccumulateGrad]
	13985443952 -> 13985212992
	13881751120 [label="trunk_output.block3.block3-12.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881751120 -> 13985443952
	13985443952 [label=AccumulateGrad]
	13985212752 -> 13985212704
	13985212752 [label=NativeBatchNormBackward0]
	13985212848 -> 13985212752
	13985212848 [label=ConvolutionBackward0]
	13985445680 -> 13985212848
	13985445680 [label=ReluBackward0]
	13985446160 -> 13985445680
	13985446160 [label=NativeBatchNormBackward0]
	13985446544 -> 13985446160
	13985446544 [label=ConvolutionBackward0]
	13985446736 -> 13985446544
	13985446736 [label=ReluBackward0]
	13985446880 -> 13985446736
	13985446880 [label=NativeBatchNormBackward0]
	13985446976 -> 13985446880
	13985446976 [label=ConvolutionBackward0]
	13985212800 -> 13985446976
	13985447168 -> 13985446976
	13881751504 [label="trunk_output.block3.block3-13.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881751504 -> 13985447168
	13985447168 [label=AccumulateGrad]
	13985446928 -> 13985446880
	13881751600 [label="trunk_output.block3.block3-13.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881751600 -> 13985446928
	13985446928 [label=AccumulateGrad]
	13985446784 -> 13985446880
	13881751696 [label="trunk_output.block3.block3-13.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881751696 -> 13985446784
	13985446784 [label=AccumulateGrad]
	13985446688 -> 13985446544
	13881752080 [label="trunk_output.block3.block3-13.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13881752080 -> 13985446688
	13985446688 [label=AccumulateGrad]
	13985446592 -> 13985446160
	13881752176 [label="trunk_output.block3.block3-13.f.b.1.weight
 (432)" fillcolor=lightblue]
	13881752176 -> 13985446592
	13985446592 [label=AccumulateGrad]
	13985446448 -> 13985446160
	13881752272 [label="trunk_output.block3.block3-13.f.b.1.bias
 (432)" fillcolor=lightblue]
	13881752272 -> 13985446448
	13985446448 [label=AccumulateGrad]
	13985445728 -> 13985212848
	13881752656 [label="trunk_output.block3.block3-13.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881752656 -> 13985445728
	13985445728 [label=AccumulateGrad]
	13985212896 -> 13985212752
	13881752752 [label="trunk_output.block3.block3-13.f.c.1.weight
 (432)" fillcolor=lightblue]
	13881752752 -> 13985212896
	13985212896 [label=AccumulateGrad]
	13985444624 -> 13985212752
	13881752848 [label="trunk_output.block3.block3-13.f.c.1.bias
 (432)" fillcolor=lightblue]
	13881752848 -> 13985444624
	13985444624 [label=AccumulateGrad]
	13985212512 -> 13985212464
	13985212512 [label=NativeBatchNormBackward0]
	13985212608 -> 13985212512
	13985212608 [label=ConvolutionBackward0]
	13985446352 -> 13985212608
	13985446352 [label=ReluBackward0]
	13985446832 -> 13985446352
	13985446832 [label=NativeBatchNormBackward0]
	13985447216 -> 13985446832
	13985447216 [label=ConvolutionBackward0]
	13985447408 -> 13985447216
	13985447408 [label=ReluBackward0]
	13985447552 -> 13985447408
	13985447552 [label=NativeBatchNormBackward0]
	13985447648 -> 13985447552
	13985447648 [label=ConvolutionBackward0]
	13985212560 -> 13985447648
	13985447840 -> 13985447648
	13881753232 [label="trunk_output.block3.block3-14.f.a.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13881753232 -> 13985447840
	13985447840 [label=AccumulateGrad]
	13985447600 -> 13985447552
	13881753328 [label="trunk_output.block3.block3-14.f.a.1.weight
 (432)" fillcolor=lightblue]
	13881753328 -> 13985447600
	13985447600 [label=AccumulateGrad]
	13985447456 -> 13985447552
	13881753424 [label="trunk_output.block3.block3-14.f.a.1.bias
 (432)" fillcolor=lightblue]
	13881753424 -> 13985447456
	13985447456 [label=AccumulateGrad]
	13985447360 -> 13985447216
	13891846416 [label="trunk_output.block3.block3-14.f.b.0.weight
 (432, 48, 3, 3)" fillcolor=lightblue]
	13891846416 -> 13985447360
	13985447360 [label=AccumulateGrad]
	13985447264 -> 13985446832
	13891846512 [label="trunk_output.block3.block3-14.f.b.1.weight
 (432)" fillcolor=lightblue]
	13891846512 -> 13985447264
	13985447264 [label=AccumulateGrad]
	13985447120 -> 13985446832
	13891846608 [label="trunk_output.block3.block3-14.f.b.1.bias
 (432)" fillcolor=lightblue]
	13891846608 -> 13985447120
	13985447120 [label=AccumulateGrad]
	13985446400 -> 13985212608
	13891846992 [label="trunk_output.block3.block3-14.f.c.0.weight
 (432, 432, 1, 1)" fillcolor=lightblue]
	13891846992 -> 13985446400
	13985446400 [label=AccumulateGrad]
	13985212656 -> 13985212512
	13891847088 [label="trunk_output.block3.block3-14.f.c.1.weight
 (432)" fillcolor=lightblue]
	13891847088 -> 13985212656
	13985212656 [label=AccumulateGrad]
	13985445296 -> 13985212512
	13891847184 [label="trunk_output.block3.block3-14.f.c.1.bias
 (432)" fillcolor=lightblue]
	13891847184 -> 13985445296
	13985445296 [label=AccumulateGrad]
	13985210496 -> 13985210688
	13891847568 [label="trunk_output.block4.block4-0.proj.0.weight
 (1008, 432, 1, 1)" fillcolor=lightblue]
	13891847568 -> 13985210496
	13985210496 [label=AccumulateGrad]
	13985210736 -> 13985210928
	13891847664 [label="trunk_output.block4.block4-0.proj.1.weight
 (1008)" fillcolor=lightblue]
	13891847664 -> 13985210736
	13985210736 [label=AccumulateGrad]
	13985210784 -> 13985210928
	13891847760 [label="trunk_output.block4.block4-0.proj.1.bias
 (1008)" fillcolor=lightblue]
	13891847760 -> 13985210784
	13985210784 [label=AccumulateGrad]
	13985210976 -> 13985211024
	13985210976 [label=NativeBatchNormBackward0]
	13985210352 -> 13985210976
	13985210352 [label=ConvolutionBackward0]
	13985447312 -> 13985210352
	13985447312 [label=ReluBackward0]
	13985447792 -> 13985447312
	13985447792 [label=NativeBatchNormBackward0]
	13985447504 -> 13985447792
	13985447504 [label=ConvolutionBackward0]
	13985447744 -> 13985447504
	13985447744 [label=ReluBackward0]
	13985562880 -> 13985447744
	13985562880 [label=NativeBatchNormBackward0]
	13985562976 -> 13985562880
	13985562976 [label=ConvolutionBackward0]
	13985210400 -> 13985562976
	13985563168 -> 13985562976
	13891848144 [label="trunk_output.block4.block4-0.f.a.0.weight
 (1008, 432, 1, 1)" fillcolor=lightblue]
	13891848144 -> 13985563168
	13985563168 [label=AccumulateGrad]
	13985562928 -> 13985562880
	13891848240 [label="trunk_output.block4.block4-0.f.a.1.weight
 (1008)" fillcolor=lightblue]
	13891848240 -> 13985562928
	13985562928 [label=AccumulateGrad]
	13985562784 -> 13985562880
	13891848336 [label="trunk_output.block4.block4-0.f.a.1.bias
 (1008)" fillcolor=lightblue]
	13891848336 -> 13985562784
	13985562784 [label=AccumulateGrad]
	13985562736 -> 13985447504
	13891848720 [label="trunk_output.block4.block4-0.f.b.0.weight
 (1008, 48, 3, 3)" fillcolor=lightblue]
	13891848720 -> 13985562736
	13985562736 [label=AccumulateGrad]
	13985447696 -> 13985447792
	13891848816 [label="trunk_output.block4.block4-0.f.b.1.weight
 (1008)" fillcolor=lightblue]
	13891848816 -> 13985447696
	13985447696 [label=AccumulateGrad]
	13985447072 -> 13985447792
	13891848912 [label="trunk_output.block4.block4-0.f.b.1.bias
 (1008)" fillcolor=lightblue]
	13891848912 -> 13985447072
	13985447072 [label=AccumulateGrad]
	13985446640 -> 13985210352
	13891849296 [label="trunk_output.block4.block4-0.f.c.0.weight
 (1008, 1008, 1, 1)" fillcolor=lightblue]
	13891849296 -> 13985446640
	13985446640 [label=AccumulateGrad]
	13985210544 -> 13985210976
	13891849392 [label="trunk_output.block4.block4-0.f.c.1.weight
 (1008)" fillcolor=lightblue]
	13891849392 -> 13985210544
	13985210544 [label=AccumulateGrad]
	13985210640 -> 13985210976
	13891849488 [label="trunk_output.block4.block4-0.f.c.1.bias
 (1008)" fillcolor=lightblue]
	13891849488 -> 13985210640
	13985210640 [label=AccumulateGrad]
	13985211216 -> 13985211264
	13985211216 [label=NativeBatchNormBackward0]
	13985212416 -> 13985211216
	13985212416 [label=ConvolutionBackward0]
	13985447024 -> 13985212416
	13985447024 [label=ReluBackward0]
	13985562832 -> 13985447024
	13985562832 [label=NativeBatchNormBackward0]
	13985563216 -> 13985562832
	13985563216 [label=ConvolutionBackward0]
	13985563408 -> 13985563216
	13985563408 [label=ReluBackward0]
	13985563552 -> 13985563408
	13985563552 [label=NativeBatchNormBackward0]
	13985563648 -> 13985563552
	13985563648 [label=ConvolutionBackward0]
	13985211168 -> 13985563648
	13985563840 -> 13985563648
	13891849872 [label="trunk_output.block4.block4-1.f.a.0.weight
 (1008, 1008, 1, 1)" fillcolor=lightblue]
	13891849872 -> 13985563840
	13985563840 [label=AccumulateGrad]
	13985563600 -> 13985563552
	13891849968 [label="trunk_output.block4.block4-1.f.a.1.weight
 (1008)" fillcolor=lightblue]
	13891849968 -> 13985563600
	13985563600 [label=AccumulateGrad]
	13985563456 -> 13985563552
	13891850064 [label="trunk_output.block4.block4-1.f.a.1.bias
 (1008)" fillcolor=lightblue]
	13891850064 -> 13985563456
	13985563456 [label=AccumulateGrad]
	13985563360 -> 13985563216
	13891850448 [label="trunk_output.block4.block4-1.f.b.0.weight
 (1008, 48, 3, 3)" fillcolor=lightblue]
	13891850448 -> 13985563360
	13985563360 [label=AccumulateGrad]
	13985563264 -> 13985562832
	13891850544 [label="trunk_output.block4.block4-1.f.b.1.weight
 (1008)" fillcolor=lightblue]
	13891850544 -> 13985563264
	13985563264 [label=AccumulateGrad]
	13985563120 -> 13985562832
	13891850640 [label="trunk_output.block4.block4-1.f.b.1.bias
 (1008)" fillcolor=lightblue]
	13891850640 -> 13985563120
	13985563120 [label=AccumulateGrad]
	13985447888 -> 13985212416
	13891851024 [label="trunk_output.block4.block4-1.f.c.0.weight
 (1008, 1008, 1, 1)" fillcolor=lightblue]
	13891851024 -> 13985447888
	13985447888 [label=AccumulateGrad]
	13985211120 -> 13985211216
	13891851120 [label="trunk_output.block4.block4-1.f.c.1.weight
 (1008)" fillcolor=lightblue]
	13891851120 -> 13985211120
	13985211120 [label=AccumulateGrad]
	13985211072 -> 13985211216
	13891851216 [label="trunk_output.block4.block4-1.f.c.1.bias
 (1008)" fillcolor=lightblue]
	13891851216 -> 13985211072
	13985211072 [label=AccumulateGrad]
	13985211696 -> 13985211936
	13985211696 [label=TBackward0]
	13985211456 -> 13985211696
	13595377744 [label="fc.weight
 (18, 1008)" fillcolor=lightblue]
	13595377744 -> 13985211456
	13985211456 [label=AccumulateGrad]
	13985211936 -> 13985372144
}
